from pyspark.sql import SparkSession
from pyspark.sql.functions import *
spark = SparkSession.builder.appName("creating of data").getOrCreate()

df1 = spark.read.csv(r"C:\Users\Lakshmidevi\Pycrojects\psyspark\pyspark_practice\dataframe\union.csv",header=True,inferSchema=TrueharmP)
df2 = spark.read.csv(r"C:\Users\Lakshmidevi\PycharmProjects\psyspark\pyspark_practice\dataframe\u.csv",header=True,inferSchema=True)
df=df1.printSchema()
df1.show()
df=df2.printSchema()
df2.show()
# df=df1.join(df2,"id","inner")
# df.show()
# df=df1.join(df2,"id","outer")
# df.show()
# df=df1.join(df2,"id","left")
# df.show()
# df=df1.join(df2,"id","right")
# df.show()
df=df1.join(df2,"id","left_semi")
df.show()
df=df1.join(df2,"id","left_anti")
df.show()
# df = df1.join(broadcast(df2), "id")
# df.show()
union_df=df1.unionByName(df2,allowMissingColumns=True)
union_df.show()

